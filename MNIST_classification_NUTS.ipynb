{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu0 is not available  (error: Unable to get the number of gpus available: CUDA driver version is insufficient for CUDA runtime version)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import theano\n",
    "floatX = theano.config.floatX\n",
    "import pymc3 as pm\n",
    "import theano.tensor as T\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import scipy.io as sio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist = fetch_mldata('MNIST original', data_home='.')\n",
    "### to download MNIST data, uncomment the line above and run ###\n",
    "mnist = sio.loadmat('mldata/mnist-original.mat')\n",
    "data = mnist['data'].T\n",
    "label = mnist['label'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data, label, test_size=1.0/7)\n",
    "X_train = X_train.astype(floatX)\n",
    "X_test = X_test.astype(floatX)\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_nn(ann_input, ann_output):\n",
    "    n_hidden = 5\n",
    "    n_classes = 10\n",
    "\n",
    "    # Initialize random weights between each layer\n",
    "    init_1 = np.random.randn(data.shape[1], n_hidden).astype(floatX)\n",
    "    init_2 = np.random.randn(n_hidden, n_classes).astype(floatX)\n",
    "    init_out = np.random.randn(n_classes).astype(floatX)\n",
    "\n",
    "    with pm.Model() as neural_network:\n",
    "        # Weights from input to hidden layer\n",
    "        weights_in_1 = pm.Normal('w_in_1', 0, sd=1,\n",
    "                                 shape=(data.shape[1], n_hidden),\n",
    "                                 testval=init_1)\n",
    "\n",
    "        # Weights from 1st to 2nd layer\n",
    "        weights_1_2 = pm.Normal('w_1_2', 0, sd=1,\n",
    "                                shape=(n_hidden, n_classes),\n",
    "                                testval=init_2)\n",
    "\n",
    "        # Weights from hidden layer to output\n",
    "        weights_2_out = pm.Normal('w_2_out', 0, sd=1,\n",
    "                                  shape=(n_classes,),\n",
    "                                  testval=init_out)\n",
    "\n",
    "        # Build neural-network using tanh activation function\n",
    "        act_1 = pm.math.tanh(pm.math.dot(ann_input,\n",
    "                                         weights_in_1))\n",
    "        act_2 = pm.math.tanh(pm.math.dot(act_1,\n",
    "                                         weights_1_2))\n",
    "        act_out = pm.math.sigmoid(pm.math.dot(act_2,\n",
    "                                              weights_2_out))\n",
    "\n",
    "        # Categorical classification (10 classes)\n",
    "        out = pm.Categorical('out',\n",
    "                           act_out,\n",
    "                           observed=ann_output,\n",
    "                           total_size=Y_train.shape[0] # IMPORTANT for minibatches\n",
    "                          )\n",
    "    return neural_network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_input = theano.shared(X_train)\n",
    "ann_output = theano.shared(Y_train)\n",
    "neural_network = construct_nn(ann_input, ann_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequential sampling (1 chains in 1 job)\n",
      "CompoundStep\n",
      ">Metropolis: [w_2_out]\n",
      ">Metropolis: [w_1_2]\n",
      ">Metropolis: [w_in_1]\n",
      "  1%|          | 69/10500 [01:00<2:32:12,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "with neural_network:\n",
    "    step = pm.Metropolis() # Should be NUTS, but veeeeeeeery slow\n",
    "    trace = pm.sample(10000, init='advi', step=step, chains=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
